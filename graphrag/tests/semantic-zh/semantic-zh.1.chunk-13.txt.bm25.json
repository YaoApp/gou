{
  "dimension": 384,
  "file": "semantic-zh.1.chunk-13.txt",
  "full_path": "/Users/max/Yao/gou/graphrag/tests/semantic-zh/semantic-zh.1.chunk-13.txt",
  "generated_at": "2025-06-21T13:42:13+08:00",
  "model": "Qdrant/bm25",
  "sparse_embedding": {
    "indices": [
      1992806525,
      1761162586,
      941358305,
      5990199,
      879738864,
      1311642283,
      748979018,
      307762834,
      71923455,
      1866681274,
      1188412670,
      1363801701,
      404558398,
      1268751793,
      1351675586,
      35721292,
      609270800,
      1257441684,
      913951781,
      1472398246,
      1172383616,
      1052767088,
      14784032,
      277842900,
      802643101,
      1656472675,
      243905464,
      245221680,
      553238108,
      1561913592,
      1810453357,
      2031875777,
      376887513,
      645919289,
      939559855,
      2064885619,
      997012898,
      730744740,
      494071086,
      731532567,
      764297089,
      1863100986,
      218215762,
      1724271785,
      332723732,
      2045916435,
      1634657082,
      945750211,
      210017096,
      1162769259
    ],
    "values": [
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.7210084,
      1.7210084,
      1.4132999,
      1.7210084,
      1.8556837,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.7210084,
      1.4132999,
      2.013226,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.7210084,
      1.4132999,
      1.9312474,
      1.7210084,
      1.8556837,
      1.8556837,
      1.4132999,
      1.7210084,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.7210084,
      1.4132999,
      1.4132999,
      1.7210084,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999,
      1.4132999
    ]
  },
  "text_length": 737,
  "type": "sparse",
  "usage": {
    "total_tokens": 2433,
    "prompt_tokens": 2433,
    "total_texts": 157
  }
}