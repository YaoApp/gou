{
  "dimension": 384,
  "file": "semantic-en.2.chunk-40.txt",
  "full_path": "/Users/max/Yao/gou/graphrag/tests/semantic-en/semantic-en.2.chunk-40.txt",
  "generated_at": "2025-06-21T13:42:45+08:00",
  "model": "Qdrant/bm25",
  "sparse_embedding": {
    "indices": [
      60951357,
      1748033122,
      856081220,
      1376864891,
      1656472675,
      764297089,
      2031875777,
      516830072,
      1401524087,
      274844176,
      1079027559,
      2087367745,
      481329573,
      783977789,
      2142141949,
      1508140589,
      1008104609,
      659326392,
      1563718956,
      422208903,
      1052767088,
      728487644,
      79077098,
      1491351846,
      301705055,
      640124220,
      149060006,
      366928855,
      108090961,
      290516589,
      1223115691,
      2065015680,
      1866681274,
      1188412670,
      1634657082,
      477044863,
      569095015,
      842430915,
      1122108788,
      1075114912,
      1418282702,
      243905464,
      510459093,
      1612531086,
      150695120,
      161561013,
      953378023,
      108710752,
      819028769,
      1271291307,
      286434387,
      1853176582
    ],
    "values": [
      1.436002,
      1.436002,
      1.7377353,
      1.436002,
      1.7377353,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.7377353,
      1.8686131,
      1.8686131,
      1.436002,
      1.436002,
      1.436002,
      1.7377353,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.7377353,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.7377353,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.9417342,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.436002,
      1.7377353,
      1.436002,
      1.436002
    ]
  },
  "text_length": 611,
  "type": "sparse",
  "usage": {
    "total_tokens": 7281,
    "prompt_tokens": 7281,
    "total_texts": 191
  }
}